{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e70c932-1b48-4655-be2c-e270c97deef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Can we use Bagging for regression problems?\n",
    "# Yes, Bagging can be used for regression to reduce variance by averaging predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efbf124e-48f7-464d-8031-8a0e2fea4d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. What is the difference between multiple model training and single model training?\n",
    "# Multiple model training (ensemble learning) improves generalization and reduces overfitting,\n",
    "# while single model training is simpler but may overfit or underperform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e0bd84-0a4f-4645-972e-0b633a280893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Explain the concept of feature randomness in Random Forest.\n",
    "# In Random Forest, each tree is trained on a random subset of features,\n",
    "# increasing model diversity and reducing correlation among trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfdd0714-b6ad-4614-a8fe-f4abd669f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. How can you measure the importance of features in a Random Forest model?\n",
    "# Feature importance is measured using Gini impurity decrease or permutation importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f987ada-eb3a-42a6-8452-f4dc17f40c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Explain the working principle of a Bagging Classifier.\n",
    "# Bagging trains multiple models on different bootstrap samples and averages their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e87ff07-0443-493d-8d72-2d7696022816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. How do you evaluate a Bagging Classifierâ€™s performance?\n",
    "# Use accuracy, precision, recall, F1-score, and AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "136e43b3-dc34-4b6a-9fcc-8224a259bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. How does a Bagging Regressor work?\n",
    "# It trains multiple regression models on different samples and averages their outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0f69e8c-4583-4ced-aeeb-04b28c1ef6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. What is the main advantage of ensemble techniques?\n",
    "# They improve accuracy and reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ec7a285-2646-433c-88d3-d574e76df118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. What is the main challenge of ensemble methods?\n",
    "# They are computationally expensive and harder to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "694e41d8-8a5f-4c66-b0b2-d0c6884f4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Explain the key idea behind ensemble techniques.\n",
    "# Combining multiple weak models to form a strong model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f780d124-79fa-4d90-825c-e324fbf75116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. What is a Random Forest Classifier?\n",
    "# A Random Forest Classifier is an ensemble of decision trees that use bagging and feature randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a2ad39c-8869-4db4-8cdd-91c03c953a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. What are the main types of ensemble techniques?\n",
    "# 1. Bagging\n",
    "# 2. Boosting\n",
    "# 3. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce4c469d-c7e5-4c66-9da5-cf26f3b274dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. What is ensemble learning in machine learning?\n",
    "# It is a technique that combines multiple models to improve predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af9f294d-1e66-40b4-be13-7b99ef8bca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. When should we avoid using ensemble methods?\n",
    "# When interpretability, computation cost, or data availability is a concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e335ac4a-f811-4e13-8dc4-cd3cdbb79c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. How does Bagging help in reducing overfitting?\n",
    "# It reduces variance by training models on different subsets of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "556367b1-bf93-4ce4-bc40-9315edec30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Why is Random Forest better than a single Decision Tree?\n",
    "# It reduces overfitting and provides more robust predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1425208-1606-46dd-ab70-b1ad39f58c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. What is the role of bootstrap sampling in Bagging?\n",
    "# It creates diverse training sets, improving model robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a64d400-3fa4-466f-9d17-3fa3216eef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19. What are some real-world applications of ensemble techniques?\n",
    "# Fraud detection, recommendation systems, and medical diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2e8eeb8-b98a-4351-9837-d81c4266311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20. What is the difference between Bagging and Boosting?\n",
    "# - Bagging reduces variance (Random Forest).\n",
    "# - Boosting reduces bias by sequentially improving weak models (XGBoost, AdaBoost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbc909e-6920-4457-8064-f768cbd69483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#practical ans and i mention question number with 1 to 25 so keep in note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e59f884-4b86-435c-8f63-46ae21795997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 1. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = bagging_clf.predict(X_test)\n",
    "print(\"Bagging Classifier Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c122b0cf-b99c-4697-a750-776983a38ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Regressor MSE: 3329.483370786517\n"
     ]
    }
   ],
   "source": [
    "# 2. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "bagging_reg = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=10)\n",
    "bagging_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = bagging_reg.predict(X_test)\n",
    "print(\"Bagging Regressor MSE:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "773cecb0-4b63-43bc-8fb0-adb67b3fa094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Feature  Importance\n",
      "27  worst concave points    0.135668\n",
      "7    mean concave points    0.125306\n",
      "22       worst perimeter    0.106854\n",
      "20          worst radius    0.105790\n",
      "23            worst area    0.088837\n"
     ]
    }
   ],
   "source": [
    "# 3. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Feature Importance\n",
    "import pandas as pd\n",
    "feature_importance = pd.DataFrame({'Feature': load_breast_cancer().feature_names, 'Importance': rf_clf.feature_importances_})\n",
    "print(feature_importance.sort_values(by='Importance', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aca9cfe2-7f1f-4da0-873d-819c76807282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Score: 0.9582417582417583\n"
     ]
    }
   ],
   "source": [
    "# 4. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, oob_score=True)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# OOB Score\n",
    "print(\"OOB Score:\", rf_clf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b001d5a8-f441-4e47-92cd-0fac0c755d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "# 5. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('decision_tree', DecisionTreeClassifier()),\n",
    "    ('svm', SVC(probability=True)),\n",
    "]\n",
    "\n",
    "# Define Stacking model\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
    "\n",
    "# Train model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33ec8f0d-e9c0-4c48-bfef-956cf2ceda64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# 5. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('decision_tree', DecisionTreeClassifier()),\n",
    "    ('svm', SVC(probability=True)),\n",
    "]\n",
    "\n",
    "# Define Stacking model\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
    "\n",
    "# Train model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2a24f2a-2f70-488d-80be-227075734123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree MSE: 0.06140350877192982\n",
      "Random Forest MSE: 0.032881578947368414\n"
     ]
    }
   ],
   "source": [
    "# 6. Train a Random Forest Regressor and compare its performance with a single Decision Tree\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Train Decision Tree Regressor\n",
    "dt_reg = DecisionTreeRegressor()\n",
    "dt_reg.fit(X_train, y_train)\n",
    "dt_pred = dt_reg.predict(X_test)\n",
    "\n",
    "# Train Random Forest Regressor\n",
    "rf_reg = RandomForestRegressor(n_estimators=100)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "rf_pred = rf_reg.predict(X_test)\n",
    "\n",
    "# Compare Performance using Mean Squared Error (MSE)\n",
    "print(\"Decision Tree MSE:\", mean_squared_error(y_test, dt_pred))\n",
    "print(\"Random Forest MSE:\", mean_squared_error(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bc1f673-2b11-4df2-9a3d-2a3178fdb6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier (SVM) Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# 7. Train a Bagging Classifier using SVM as a base estimator and print accuracy\n",
    "\n",
    "svm_bagging = BaggingClassifier(estimator=SVC(probability=True), n_estimators=10)\n",
    "svm_bagging.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_bagging.predict(X_test)\n",
    "print(\"Bagging Classifier (SVM) Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18d10745-d174-4de3-8d0c-0b3b20e99f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy with 10 trees: 0.956140350877193\n",
      "Random Forest Accuracy with 50 trees: 0.9649122807017544\n",
      "Random Forest Accuracy with 100 trees: 0.956140350877193\n",
      "Random Forest Accuracy with 200 trees: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# 8. Train a Random Forest Classifier with different numbers of trees and compare accuracy\n",
    "\n",
    "n_trees = [10, 50, 100, 200]\n",
    "for n in n_trees:\n",
    "    rf_clf = RandomForestClassifier(n_estimators=n)\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    y_pred = rf_clf.predict(X_test)\n",
    "    print(f\"Random Forest Accuracy with {n} trees:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a4ac39a-7fc1-4476-97bc-4bc136343fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier (Logistic Regression) AUC Score: 0.9980347199475925\n"
     ]
    }
   ],
   "source": [
    "# 9. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "log_bagging = BaggingClassifier(estimator=LogisticRegression(), n_estimators=10)\n",
    "log_bagging.fit(X_train, y_train)\n",
    "\n",
    "y_prob = log_bagging.predict_proba(X_test)[:, 1]\n",
    "print(\"Bagging Classifier (Logistic Regression) AUC Score:\", roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8d1f18f-5ed7-4f00-a196-d69f8a61375c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature  Importance\n",
      "8      s5    0.315629\n",
      "2     bmi    0.276249\n",
      "3      bp    0.087085\n",
      "9      s6    0.070775\n",
      "0     age    0.057496\n",
      "5      s2    0.055368\n",
      "6      s3    0.051191\n",
      "4      s1    0.047251\n",
      "7      s4    0.027056\n",
      "1     sex    0.011901\n"
     ]
    }
   ],
   "source": [
    "# 10. Train a Random Forest Regressor and analyze feature importance scores\n",
    "\n",
    "# Load dataset\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "data = load_diabetes()\n",
    "X, y = data.data, data.target\n",
    "feature_names = data.feature_names  # Extract feature names\n",
    "\n",
    "# Train Random Forest Regressor\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_reg.fit(X, y)\n",
    "\n",
    "# Ensure feature importance matches the number of features\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names[:len(rf_reg.feature_importances_)],  # Match length\n",
    "    'Importance': rf_reg.feature_importances_\n",
    "})\n",
    "\n",
    "# Print sorted feature importance\n",
    "print(feature_importance.sort_values(by='Importance', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "180894d1-08fd-482b-b7b2-6091d88fdf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.956140350877193\n",
      "Random Forest Accuracy: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# 11. Train an ensemble model using both Bagging and Random Forest and compare accuracy\n",
    "\n",
    "bagging = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10)\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Train models\n",
    "bagging.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict and compare accuracy\n",
    "y_pred_bagging = bagging.predict(X_test)\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "\n",
    "print(\"Bagging Accuracy:\", accuracy_score(y_test, y_pred_bagging))\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "390ca152-2d9f-401f-b5b6-db9647cbdefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'n_estimators': 200}\n",
      "Best accuracy: 0.9626373626373625\n"
     ]
    }
   ],
   "source": [
    "# 12. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, None]}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ca821ed-a375-4ec7-a596-0593308c3a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Regressor MSE with 5 estimators: 0.03649122807017544\n",
      "Bagging Regressor MSE with 10 estimators: 0.03552631578947369\n",
      "Bagging Regressor MSE with 50 estimators: 0.028543859649122812\n",
      "Bagging Regressor MSE with 100 estimators: 0.03493947368421053\n"
     ]
    }
   ],
   "source": [
    "# 13. Train a Bagging Regressor with different numbers of base estimators and compare performance\n",
    "\n",
    "n_estimators = [5, 10, 50, 100]\n",
    "for n in n_estimators:\n",
    "    bag_reg = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=n)\n",
    "    bag_reg.fit(X_train, y_train)\n",
    "    y_pred = bag_reg.predict(X_test)\n",
    "    print(f\"Bagging Regressor MSE with {n} estimators:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44ccf6ec-2772-4e46-833a-41488e6cceda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 0.9649122807017544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 15. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=[\n",
    "    ('random_forest', RandomForestClassifier(n_estimators=100)),\n",
    "    ('log_reg', LogisticRegression())\n",
    "], final_estimator=LogisticRegression())\n",
    "\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5676d88a-d389-4e2a-aea5-bbfbb4fa9d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Regressor MSE with 50.0% bootstrap samples: 0.030175438596491227\n",
      "Bagging Regressor MSE with 70.0% bootstrap samples: 0.034210526315789476\n",
      "Bagging Regressor MSE with 100.0% bootstrap samples: 0.041842105263157896\n"
     ]
    }
   ],
   "source": [
    "# 16. Train a Bagging Regressor with different levels of bootstrap samples and compare performance\n",
    "\n",
    "bootstrap_samples = [0.5, 0.7, 1.0]\n",
    "for bs in bootstrap_samples:\n",
    "    bag_reg = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=10, max_samples=bs)\n",
    "    bag_reg.fit(X_train, y_train)\n",
    "    y_pred = bag_reg.predict(X_test)\n",
    "    print(f\"Bagging Regressor MSE with {bs*100}% bootstrap samples:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47944b16-4f73-4e73-8611-c9d5645d655d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Important Features in Random Forest:\n",
      "                 Feature  Importance\n",
      "20          worst radius    0.129299\n",
      "22       worst perimeter    0.120378\n",
      "23            worst area    0.110846\n",
      "27  worst concave points    0.105682\n",
      "7    mean concave points    0.087796\n"
     ]
    }
   ],
   "source": [
    "# 17. Train a Random Forest Classifier and print the top 5 most important features\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({'Feature': load_breast_cancer().feature_names, 'Importance': rf_clf.feature_importances_})\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print top 5 features\n",
    "print(\"Top 5 Important Features in Random Forest:\")\n",
    "print(feature_importance.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7bb9a30c-2f34-4268-a462-cdc746652d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9561\n",
      "Recall: 0.9561\n",
      "F1-Score: 0.9560\n"
     ]
    }
   ],
   "source": [
    "# 18. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Train Bagging Classifier\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "y_pred = bagging_clf.predict(X_test)\n",
    "\n",
    "# Compute metrics\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "063825a1-22d7-42a2-a47b-fae4235f1a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy with max_depth=3: 0.9649122807017544\n",
      "Random Forest Accuracy with max_depth=5: 0.9649122807017544\n",
      "Random Forest Accuracy with max_depth=10: 0.9649122807017544\n",
      "Random Forest Accuracy with max_depth=None: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "# 19. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy\n",
    "\n",
    "max_depth_values = [3, 5, 10, None]\n",
    "for depth in max_depth_values:\n",
    "    rf_clf = RandomForestClassifier(n_estimators=100, max_depth=depth)\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    y_pred = rf_clf.predict(X_test)\n",
    "    print(f\"Random Forest Accuracy with max_depth={depth}:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "092b3818-5ffe-4c4a-a79f-8f0671d17d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Regressor MSE with DecisionTreeRegressor: 0.03657894736842106\n",
      "Bagging Regressor MSE with KNeighborsRegressor: 0.03813333333333333\n"
     ]
    }
   ],
   "source": [
    "# 20. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "base_estimators = [DecisionTreeRegressor(), KNeighborsRegressor()]\n",
    "for estimator in base_estimators:\n",
    "    bag_reg = BaggingRegressor(estimator=estimator, n_estimators=10)\n",
    "    bag_reg.fit(X_train, y_train)\n",
    "    y_pred = bag_reg.predict(X_test)\n",
    "    print(f\"Bagging Regressor MSE with {estimator.__class__.__name__}:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3efa55f-d143-4219-b496-e413deb2aba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest ROC-AUC Score: 0.995250573206682\n"
     ]
    }
   ],
   "source": [
    "# 21. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_prob = rf_clf.predict_proba(X_test)[:, 1]\n",
    "print(\"Random Forest ROC-AUC Score:\", roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be157cd5-85b8-4a7d-8ffa-ac7aaad5cec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Cross-Validation Accuracy: 0.0045199182839632274\n"
     ]
    }
   ],
   "source": [
    "# 22. Train a Bagging Classifier and evaluate its performance using cross-validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(bagging_clf, X, y, cv=5, scoring='accuracy')\n",
    "print(\"Bagging Classifier Cross-Validation Accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "040f7fba-e10c-42fc-9604-6eb23b718f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABQyElEQVR4nO3deVxU5f4H8M8wwAw7KquIIrjggmKohEuokQjGdSklVyT35VaSqZiKtoiWEWZued3yehMX8loappgVLmluae6KggoIGqAgIMzz+8Mfcx0ZEGiYAc/n/XrN6+U885wz33MYmI9neR6ZEEKAiIiISEKMDF0AERERkb4xABEREZHkMAARERGR5DAAERERkeQwABEREZHkMAARERGR5DAAERERkeQwABEREZHkMAARERGR5DAA0XNt1KhRcHNzq9IyBw4cgEwmw4EDB2qkprquR48e6NGjh/r59evXIZPJsH79eoPVZGgPHjzAmDFj4OTkBJlMhnfeecfQJekdPwdU1zAAkU6tX78eMplM/VAqlWjRogWmTJmCjIwMQ5dX65V+iZQ+jIyMUL9+fQQFBeHw4cOGLk8nMjIyMG3aNHh6esLc3BwWFhbw8fHBRx99hOzsbEOXVy0LFizA+vXrMXHiRGzcuBEjRoyo0fdzc3PT+JxYWFigc+fO+Prrr2v0feuap/fTk4+CggJDl1fGoUOHMG/evDr7e1DXGBu6AHo+ffDBB2jatCkKCgqQlJSEFStWYPfu3Th79izMzc31Vsfq1auhUqmqtMxLL72Ehw8fwtTUtIaqerYhQ4YgODgYJSUluHTpEpYvX46ePXvi2LFj8PLyMlhdf9exY8cQHByMBw8eYPjw4fDx8QEA/P7771i4cCF++eUX/Pjjjwausur279+PF198EVFRUXp7T29vb7z77rsAgLS0NPzrX/9CWFgYCgsLMXbsWL3VUds9uZ+eZMjf7/IcOnQI8+fPx6hRo2Bra2vocp57DEBUI4KCgtCxY0cAwJgxY9CgQQPExMTgv//9L4YMGaJ1mby8PFhYWOi0DhMTkyovY2RkBKVSqdM6quqFF17A8OHD1c+7d++OoKAgrFixAsuXLzdgZdWXnZ2NAQMGQC6X4+TJk/D09NR4/eOPP8bq1at18l418VmqyJ07d9C6dWudra+4uBgqlarCL2kXFxeNz8ioUaPg7u6Ozz//nAHoCU/vJ11RqVQoKioy+N8Kqj6eAiO96NWrFwAgOTkZwOM/1paWlrh69SqCg4NhZWWFYcOGAXj8hyU2NhZt2rSBUqmEo6Mjxo8fj7/++qvMen/44Qf4+/vDysoK1tbW6NSpE/7zn/+oX9d2DdDmzZvh4+OjXsbLywtLlixRv17eNUBbt26Fj48PzMzMYGdnh+HDh+PWrVsafUq369atW+jfvz8sLS1hb2+PadOmoaSkpNr7r3v37gCAq1evarRnZ2fjnXfegaurKxQKBZo1a4ZFixaVOeqlUqmwZMkSeHl5QalUwt7eHn369MHvv/+u7rNu3Tr06tULDg4OUCgUaN26NVasWFHtmp+2atUq3Lp1CzExMWXCDwA4Ojpi9uzZ6ucymQzz5s0r08/NzQ2jRo1SPy897frzzz9j0qRJcHBwQKNGjbBt2zZ1u7ZaZDIZzp49q267cOECXn/9ddSvXx9KpRIdO3bEzp07K9ym0s9KcnIydu3apT69cv36dQCPg9Ho0aPh6OgIpVKJ9u3bY8OGDRrrKD3tuXjxYsTGxsLDwwMKhQLnzp2r8L2fZm9vD09PzzKfkV9//RWDBg1C48aNoVAo4OrqiqlTp+Lhw4ca/ary2c3OzsaoUaNgY2MDW1tbhIWFlXvaZv/+/ejevTssLCxga2uLfv364fz58xp95s2bB5lMhkuXLmH48OGwsbGBvb095syZAyEEUlNT0a9fP1hbW8PJyQmfffZZlfZNRfLy8vDuu++qf4datmyJxYsXQwih0U8mk2HKlCnYtGkT2rRpA4VCgYSEBADArVu38Oabb8LR0REKhQJt2rTB2rVry7zX0qVL0aZNG5ibm6NevXro2LGj+u/VvHnz8N577wEAmjZtWuazRLrHI0CkF6V/lBs0aKBuKy4uRmBgILp164bFixerT42NHz8e69evR3h4ON566y0kJyfjyy+/xMmTJ3Hw4EH1UZ3169fjzTffRJs2bRAZGQlbW1ucPHkSCQkJGDp0qNY69u7diyFDhuDll1/GokWLAADnz5/HwYMH8fbbb5dbf2k9nTp1QnR0NDIyMrBkyRIcPHgQJ0+e1DhcXVJSgsDAQPj6+mLx4sXYt28fPvvsM3h4eGDixInV2n+lfwTr1aunbsvPz4e/vz9u3bqF8ePHo3Hjxjh06BAiIyORlpaG2NhYdd/Ro0dj/fr1CAoKwpgxY1BcXIxff/0VR44cUR+pW7FiBdq0aYN//OMfMDY2xnfffYdJkyZBpVJh8uTJ1ar7STt37oSZmRlef/31v70ubSZNmgR7e3vMnTsXeXl56Nu3LywtLbFlyxb4+/tr9I2Li0ObNm3Qtm1bAMCff/6Jrl27wsXFBTNnzoSFhQW2bNmC/v37Y/v27RgwYIDW92zVqhU2btyIqVOnolGjRupTLfb29nj48CF69OiBK1euYMqUKWjatCm2bt2KUaNGITs7u8znbd26dSgoKMC4ceOgUChQv379Km1/cXExbt68qfEZAR4H9/z8fEycOBENGjTA0aNHsXTpUty8eRNbt27V6FuZz64QAv369UNSUhImTJiAVq1a4dtvv0VYWFiZmvbt24egoCC4u7tj3rx5ePjwIZYuXYquXbvixIkTZf5zEhoailatWmHhwoXYtWsXPvroI9SvXx+rVq1Cr169sGjRImzatAnTpk1Dp06d8NJLLz1zvzx69AhZWVkabebm5jA3N4cQAv/4xz/w008/YfTo0fD29saePXvw3nvv4datW/j88881ltu/fz+2bNmCKVOmwM7ODm5ubsjIyMCLL76oDkj29vb44YcfMHr0aOTm5qoviF+9ejXeeustvP7663j77bdRUFCAP/74A7/99huGDh2KgQMH4tKlS/jmm2/w+eefw87ODsDjzxLVEEGkQ+vWrRMAxL59+0RmZqZITU0VmzdvFg0aNBBmZmbi5s2bQgghwsLCBAAxc+ZMjeV//fVXAUBs2rRJoz0hIUGjPTs7W1hZWQlfX1/x8OFDjb4qlUr977CwMNGkSRP187fffltYW1uL4uLicrfhp59+EgDETz/9JIQQoqioSDg4OIi2bdtqvNf3338vAIi5c+dqvB8A8cEHH2iss0OHDsLHx6fc9yyVnJwsAIj58+eLzMxMkZ6eLn799VfRqVMnAUBs3bpV3ffDDz8UFhYW4tKlSxrrmDlzppDL5SIlJUUIIcT+/fsFAPHWW2+Veb8n91V+fn6Z1wMDA4W7u7tGm7+/v/D39y9T87p16yrctnr16on27dtX2OdJAERUVFSZ9iZNmoiwsDD189LPXLdu3cr8XIcMGSIcHBw02tPS0oSRkZHGz+jll18WXl5eoqCgQN2mUqlEly5dRPPmzZ9Za5MmTUTfvn012mJjYwUA8e9//1vdVlRUJPz8/ISlpaXIzc0VQvxv/1lbW4s7d+48871K3693794iMzNTZGZmijNnzogRI0YIAGLy5MkafbX9XKOjo4VMJhM3btxQt1X2s7tjxw4BQHzyySfqtuLiYtG9e/cynwNvb2/h4OAg7t69q247ffq0MDIyEiNHjlS3RUVFCQBi3LhxGuts1KiRkMlkYuHCher2v/76S5iZmWl8BiraTwDKPEo/V6Xb8tFHH2ks9/rrrwuZTCauXLmibgMgjIyMxJ9//qnRd/To0cLZ2VlkZWVptL/xxhvCxsZGvf/79esn2rRpU2G9n376qQAgkpOTn7lt9PfxFBjViICAANjb28PV1RVvvPEGLC0t8e2338LFxUWj39NHRLZu3QobGxu88soryMrKUj98fHxgaWmJn376CcDjIzn379/HzJkzy5yDl8lk5dZla2uLvLw87N27t9Lb8vvvv+POnTuYNGmSxnv17dsXnp6e2LVrV5llJkyYoPG8e/fuuHbtWqXfMyoqCvb29nByckL37t1x/vx5fPbZZxpHT7Zu3Yru3bujXr16GvsqICAAJSUl+OWXXwAA27dvh0wm03qB7pP7yszMTP3vnJwcZGVlwd/fH9euXUNOTk6lay9Pbm4urKys/vZ6yjN27FjI5XKNttDQUNy5c0fjdOa2bdugUqkQGhoKALh37x7279+PwYMH4/79++r9ePfuXQQGBuLy5ctlTnVWxu7du+Hk5KRxzZuJiQneeustPHjwoMypuddee61K/9v/8ccfYW9vD3t7e3h5eWHjxo0IDw/Hp59+qtHvyZ9rXl4esrKy0KVLFwghcPLkyTLrfdZnd/fu3TA2Ntb43ZXL5fjnP/+psVxaWhpOnTqFUaNGaRzNateuHV555RXs3r27zHuPGTNGY50dO3aEEAKjR49Wt9va2qJly5aV/n3y9fXF3r17NR4jR45Ub4tcLsdbb72lscy7774LIQR++OEHjXZ/f3+Na72EENi+fTtCQkIghND4PQwMDEROTg5OnDihrvvmzZs4duxYpeqmmsdTYFQjli1bhhYtWsDY2BiOjo5o2bIljIw087axsTEaNWqk0Xb58mXk5OTAwcFB63rv3LkD4H+n1EpPYVTWpEmTsGXLFgQFBcHFxQW9e/fG4MGD0adPn3KXuXHjBgCgZcuWZV7z9PREUlKSRlvpNTZPqlevnsY1TJmZmRrXVVhaWsLS0lL9fNy4cRg0aBAKCgqwf/9+fPHFF2Wuw7h8+TL++OOPcr80n9xXDRs2fOYplYMHDyIqKgqHDx9Gfn6+xms5OTmwsbGpcPlnsba2xv379//WOirStGnTMm19+vSBjY0N4uLi8PLLLwN4fPrL29sbLVq0AABcuXIFQgjMmTMHc+bM0bruO3fulAnvz3Ljxg00b968zOe+VatW6tefVX9FfH198dFHH6GkpARnz57FRx99hL/++qvMhdMpKSmYO3cudu7cWeY6uqeDbWU+uzdu3ICzs7PG5xUo+/tR0e9Nq1atsGfPnjIXqzdu3Fijn42NDZRKpfp00JPtd+/eLbNebezs7BAQEKD1tRs3bqBhw4Zlgnllf0aZmZnIzs7GV199ha+++krre5T+Hs6YMQP79u1D586d0axZM/Tu3RtDhw5F165dK7UdpHsMQFQjOnfurL62pDwKhaLMl4NKpYKDgwM2bdqkdZm/ez7cwcEBp06dwp49e/DDDz/ghx9+wLp16zBy5MgyF6dW19NHIbTp1KmTxh/XqKgojQt+mzdvrv6j/eqrr0Iul2PmzJno2bOner+qVCq88sormD59utb3KP2Cr4yrV6/i5ZdfhqenJ2JiYuDq6gpTU1Ps3r0bn3/+eZWHEtDG09MTp06dQlFR0d+6Bbm8i8mfPNJRSqFQoH///vj222+xfPlyZGRk4ODBg1iwYIG6T+m2TZs2DYGBgVrX3axZs2rXW1na6q/Ik1/sgYGB8PT0xKuvvoolS5YgIiICwON99corr+DevXuYMWMGPD09YWFhgVu3bmHUqFFlfq6V+ezWJG3vX15N4qmLlPXh6Z9R6f4bPny41muggMdHvIDHoerixYv4/vvvkZCQgO3bt2P58uWYO3cu5s+fX7OFk1YMQFSreHh4YN++fejatWuFXwgeHh4AgLNnz1b5y8nU1BQhISEICQmBSqXCpEmTsGrVKsyZM0frupo0aQIAuHjxovputlIXL15Uv14VmzZt0rgLx93dvcL+77//PlavXo3Zs2er7zzx8PDAgwcPyv3fbSkPDw/s2bMH9+7dK/co0HfffYfCwkLs3LlT43/hpaccdSEkJASHDx/G9u3byx0K4Un16tUrc2dRUVER0tLSqvS+oaGh2LBhAxITE3H+/HkIIdSnv4D/7XsTE5Nn7suqaNKkCf744w+oVCqNoH/hwgX167rUt29f+Pv7Y8GCBRg/fjwsLCxw5swZXLp0CRs2bFCf9gFQpVPAT2vSpAkSExPx4MEDjaNAFy9eLNNPWzvweB/Y2dnpdagCbZo0aYJ9+/bh/v37GkeBKvszsre3h5WVFUpKSir12bGwsEBoaChCQ0NRVFSEgQMH4uOPP0ZkZCSUSmWFp+9J93gNENUqgwcPRklJCT788MMyrxUXF6u/EHv37g0rKytER0eXGdG1ov8ZPn3Y3MjISP0/tMLCQq3LdOzYEQ4ODli5cqVGnx9++AHnz59H3759K7VtT+ratSsCAgLUj2cFIFtbW4wfPx579uzBqVOnADzeV4cPH8aePXvK9M/OzkZxcTGAx9eWCCG0/i+zdF+V/i/7yX2Xk5ODdevWVXnbyjNhwgQ4Ozvj3XffxaVLl8q8fufOHXz00Ufq5x4eHurrmEp99dVXVR5OICAgAPXr10dcXBzi4uLQuXNnjVMZDg4O6NGjB1atWqU1XGVmZlbp/UoFBwcjPT0dcXFx6rbi4mIsXboUlpaWZe5M04UZM2bg7t276vGUtP1chRAawz5UVXBwMIqLizWGSCgpKcHSpUs1+jk7O8Pb2xsbNmzQCLJnz57Fjz/+iODg4GrXoCulg41++eWXGu2ff/45ZDIZgoKCKlxeLpfjtddew/bt2zWGVCj15Gfn6b89pqamaN26NYQQePToEQCoAyFHgtYPHgGiWsXf3x/jx49HdHQ0Tp06hd69e8PExASXL1/G1q1bsWTJErz++uuwtrbG559/jjFjxqBTp04YOnQo6tWrh9OnTyM/P7/c01ljxozBvXv30KtXLzRq1Ag3btzA0qVL4e3trT7v/zQTExMsWrQI4eHh8Pf3x5AhQ9S3wbu5uWHq1Kk1uUvU3n77bcTGxmLhwoXYvHkz3nvvPezcuROvvvoqRo0aBR8fH+Tl5eHMmTPYtm0brl+/Djs7O/Ts2RMjRozAF198gcuXL6NPnz5QqVT49ddf0bNnT0yZMgW9e/dWHxkbP348Hjx4gNWrV8PBwaHKR1zKU69ePXz77bcIDg6Gt7e3xkjQJ06cwDfffAM/Pz91/zFjxmDChAl47bXX8Morr+D06dPYs2dPmetBnsXExAQDBw7E5s2bkZeXh8WLF5fps2zZMnTr1g1eXl4YO3Ys3N3dkZGRgcOHD+PmzZs4ffp0lbd33LhxWLVqFUaNGoXjx4/Dzc0N27Ztw8GDBxEbG1sjF4QHBQWhbdu2iImJweTJk+Hp6QkPDw9MmzYNt27dgrW1NbZv3651TK3KCgkJQdeuXTFz5kxcv34drVu3Rnx8vNYL5T/99FMEBQXBz88Po0ePVt8Gb2Njo3WMJ30LCQlBz5498f777+P69eto3749fvzxR/z3v//FO++8oz7SXJGFCxfip59+gq+vL8aOHYvWrVvj3r17OHHiBPbt24d79+4BePyfNicnJ3Tt2hWOjo44f/48vvzyS/Tt21f9WSj9fXj//ffxxhtvwMTEBCEhIQY/UvbcMsCdZ/QcK70l+dixYxX2CwsLExYWFuW+/tVXXwkfHx9hZmYmrKyshJeXl5g+fbq4ffu2Rr+dO3eKLl26CDMzM2FtbS06d+4svvnmG433efI2+G3btonevXsLBwcHYWpqKho3bizGjx8v0tLS1H2evg2+VFxcnOjQoYNQKBSifv36YtiwYerb+p+1XaW3+T5L6S3Rn376qdbXR40aJeRyufr23Pv374vIyEjRrFkzYWpqKuzs7ESXLl3E4sWLRVFRkXq54uJi8emnnwpPT09hamoq7O3tRVBQkDh+/LjGvmzXrp1QKpXCzc1NLFq0SKxdu7bMbbnVvQ2+1O3bt8XUqVNFixYthFKpFObm5sLHx0d8/PHHIicnR92vpKREzJgxQ9jZ2Qlzc3MRGBgorly5Uu5t8BV95vbu3SsACJlMJlJTU7X2uXr1qhg5cqRwcnISJiYmwsXFRbz66qti27Ztz9wmbbfBCyFERkaGCA8PF3Z2dsLU1FR4eXmV2U/P+plX5f2EEGL9+vUaP49z586JgIAAYWlpKezs7MTYsWPF6dOny/zMqvLZvXv3rhgxYoSwtrYWNjY2YsSIEeLkyZNaPwf79u0TXbt2Vf+OhoSEiHPnzml9j8zMTI328mry9/d/5i3lQlS8n0rdv39fTJ06VTRs2FCYmJiI5s2bi08//VRjiAghhNYhBkplZGSIyZMnC1dXV2FiYiKcnJzEyy+/LL766it1n1WrVomXXnpJNGjQQCgUCuHh4SHee+89jc+8EI+Ht3BxcRFGRka8Jb6GyYQwwJVkRERERAbEa4CIiIhIchiAiIiISHIYgIiIiEhyGICIiIhIchiAiIiISHIYgIiIiEhyOBCiFiqVCrdv34aVlRWHJiciIqojhBC4f/8+GjZsWGauyacxAGlx+/ZtuLq6GroMIiIiqobU1FQ0atSowj4MQFqUDkuempoKa2trA1dDRERElZGbmwtXV9dKTTXDAKRF6Wkva2trBiAiIqI6pjKXr/AiaCIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcgwagX375BSEhIWjYsCFkMhl27NjxzGUOHDiAF154AQqFAs2aNcP69evL9Fm2bBnc3NygVCrh6+uLo0eP6r54IiIiqrMMGoDy8vLQvn17LFu2rFL9k5OT0bdvX/Ts2ROnTp3CO++8gzFjxmDPnj3qPnFxcYiIiEBUVBROnDiB9u3bIzAwEHfu3KmpzaiStJyHOHQ1C2k5Dw1dCpHO1bXPd22ttzp16XJbuK6aX6a2fvakRCaEEIYuAng8cdm3336L/v37l9tnxowZ2LVrF86ePatue+ONN5CdnY2EhAQAgK+vLzp16oQvv/wSAKBSqeDq6op//vOfmDlzZqVqyc3NhY2NDXJycnQ6Ger6Q8n44LtzUAnASAZMD2yJV9s31Nn6iQzp+9O38cmei3Xm811b661OXbrcFq6r5pd5uj16oBdCOzWu1raQpqp8f9epAPTSSy/hhRdeQGxsrLpt3bp1eOedd5CTk4OioiKYm5tj27ZtGusJCwtDdnY2/vvf/2pdb2FhIQoLC9XPc3Nz4erqqtMAlJbzEF2i96NW7GwiIqo15DIZkmb2hLONmaFLqfOqEoCM9VSTTqSnp8PR0VGjzdHREbm5uXj48CH++usvlJSUaO1z4cKFctcbHR2N+fPn10jNpZKz8rSGHxMjGYyMZDX63kQ1TaUSeKQq+wmvrZ/v2lpvderS5bZwXbrbx+UtI5cBJU81lwiB61n5DEB6VqcCUE2JjIxERESE+nnpESBdampnASMZ8OTvg1wmwy8zmPqp7kvLeYiuC/fXmc93ba23OnXpclu4Lt3t4/KWiZ/khwHLDz3VDrjZmVdpO+jvq1O3wTs5OSEjI0OjLSMjA9bW1jAzM4OdnR3kcrnWPk5OTuWuV6FQwNraWuOha842Zoge6AW57PH/FuQyGRYMbFsrvxyIqqqufb5ra73VqUuX28J11fwy7V3rIXqgF548cDSqa1ODf/akqE5dAzRjxgzs3r0bZ86cUbcNHToU9+7d07gIunPnzli6dCmAxxdBN27cGFOmTDH4RdDA4/8VXM/Kh5udOT/w9Nypa5/v2lpvderS5bZwXTW/TFrOQ8z/7k8knM1A9+Z22Djat1rbQZrqzEXQDx48wJUrVwAAHTp0QExMDHr27In69eujcePGiIyMxK1bt/D1118DeHwbfNu2bTF58mS8+eab2L9/P9566y3s2rULgYGBAB7fBh8WFoZVq1ahc+fOiI2NxZYtW3DhwoUy1waVpyYDEBEREQCk3suH/6c/QSWAhHe6w9OJ3zd/V1W+vw16Cuz3339Hhw4d0KFDBwBAREQEOnTogLlz5wIA0tLSkJKSou7ftGlT7Nq1C3v37kX79u3x2Wef4V//+pc6/ABAaGgoFi9ejLlz58Lb2xunTp1CQkJCpcMPERGRPrjWN0efto8vz/jXr8kGrkZ6as0psNqER4CIiEgfTqT8hYHLD8FELsPBGb3gYK00dEl1Wp05AkRERCRlLzSuB58m9fCoRGDD4euGLkdSGICIiIgMaGz3pgCAfx9JQX5RsYGrkQ4GICIiIgN6pbUTmjQwR87DR9h2/Kahy5EMBiAiIiIDkhvJ8GbXx0eB1iQlo0TLCNK6VtVJWp/HyVs5EjQREZGBDerYCDF7L+HG3Xx8uf8KBndqVGasobSch0jOykNTO4syYwppay9P3LEURMafKTMZ69PtkcGt0KeNE3acuoWYvZcgnrPJW3kXmBa8C4yIiPRt1LqjOHAxE8DjoDE3pDWCvZxR+EiFb0/exOf7LkMIQCYDRr7YBJ2bNsDPl+5g6+83IQDIALzcygHNHKxQWFyCwmIVCh+pUFBcgsJHKhQWl+B+QTFOpWaXeW+liREKHqkqVWdtnry1zgyEWFsxABERkT5pmzusNpAbASVactE3Y1+En0cD/Rf0DM/tbPBERETPo+SsvHLDj6ncCEVaUohrPTOk/lX2mpzgtk5ws7OAwlgOpYkRFMZGUJjIoTA2wsNHJZi94yyePPRhJAOWDe2Ayf85WWaS1viJXbRM3ip7LiZvZQAiIiIysKZ2FjCSQSNoGMmApBk9IZPJtM4s/+XQDlrDyZyQ1hWenjI2kmFW/FmUCKGepDXIqyGiBxaXaS+dvHXm9jPq02y1YeJgXeApMC14CoyIiPQt7lhKmQBSerFxea9VtExFKpqkVVv7lP8cx/d/pGOCvztmBrXS/cbrCE+BERER1TGhnRrjpRb2WgNIea9VtExFnG3MtPYtr93c9HFcsFKaVGfTaiUGICIiolqivABS0WsVLUPl40CIREREJDkMQERERCQ5DEBEREQkOQxAREREVKHSWervFzwq81pdnSeMF0ETERFRueKOpeD7P9IBAKt+voamdhYat+drm1esLuA4QFpwHCAiIqLyp+hoXM8MD4pKcC+vSKPd0POEVeX7m6fAiIiISKvypuhI+ethmfADACVC4HpWvh4q+/sYgIiIiEir0ik6nmQkA5YP7YAN4Z3w1Et1ap4wBiAiIiLSytnGDNEDvSCXPY46cpkM0QO9ENyuIfxbOmBM96bqvqVTcdSVQRl5ETQRERGVq6LpNnq0dMDqX5PhWs8MWyb41ZnwAzAAERER0TM8a7oNc1PjOhV+AJ4CIyIiIgliACIiIiLJYQAiIiIiyWEAIiIiIr2pLVNn8CJoIiIi+lvyi4qRlvNQ40LotJyHSM7KQ1M7C3V7bZo6gwGIiIiIquXAxTsAgNS/Hk+ZMd7fHR1c62HPn+mIP3ELpYNIt3KygpGRDH/ezlUvqxLArPizeKmFvUHuIGMAIiIioipLy3mIfyUlq5+rBLDiwDWtfc+n39faXjp1hiECEK8BIiIioipLzsqDtunUG9ootfYf270pZE/NnWHIqTMYgIiIiKjKtM0TJpfJsGL4C1rb3+zWFAsHeqnnD5MBBp06gwGIiIiIqkzbPGELBrZFe9d6WtudbcwQ2qkxBnd0BQCMeLGJwS6ABmpBAFq2bBnc3NygVCrh6+uLo0ePltv30aNH+OCDD+Dh4QGlUon27dsjISFBo8+8efMgk8k0Hp6enjW9GURERJIT2qkxkmb2xDdjX0TSzJ7qQFNeOwBYKB5ffmypNOxlyAZ997i4OERERGDlypXw9fVFbGwsAgMDcfHiRTg4OJTpP3v2bPz73//G6tWr4enpiT179mDAgAE4dOgQOnTooO7Xpk0b7Nu3T/3c2JjXehMREdWE8uYJe9b8YYZm0CNAMTExGDt2LMLDw9G6dWusXLkS5ubmWLt2rdb+GzduxKxZsxAcHAx3d3dMnDgRwcHB+OyzzzT6GRsbw8nJSf2ws7PTx+YQERFRHWGwAFRUVITjx48jICDgf8UYGSEgIACHDx/WukxhYSGUSs2ry83MzJCUlKTRdvnyZTRs2BDu7u4YNmwYUlJSKqylsLAQubm5Gg8iIiJ6fhksAGVlZaGkpASOjo4a7Y6OjkhPT9e6TGBgIGJiYnD58mWoVCrs3bsX8fHxSEtLU/fx9fXF+vXrkZCQgBUrViA5ORndu3fH/fvaxyAAgOjoaNjY2Kgfrq6uutlIIiIi0pBXWAwAeFBQbNA6DH4RdFUsWbIEzZs3h6enJ0xNTTFlyhSEh4fDyOh/mxEUFIRBgwahXbt2CAwMxO7du5GdnY0tW7aUu97IyEjk5OSoH6mpqfrYHCIiIkmJO5aCLb8//o7deOQG4o5VfIamJhksANnZ2UEulyMjI0OjPSMjA05OTlqXsbe3x44dO5CXl4cbN27gwoULsLS0hLu7e7nvY2trixYtWuDKlSvl9lEoFLC2ttZ4EBERke6k5TxEZPwZ9fQYAo+nwjDUpKgGC0Cmpqbw8fFBYmKiuk2lUiExMRF+fn4VLqtUKuHi4oLi4mJs374d/fr1K7fvgwcPcPXqVTg7O+usdiIiIqqa5Kw8qJ4aObp0KgxDMOgpsIiICKxevRobNmzA+fPnMXHiROTl5SE8PBwAMHLkSERGRqr7//bbb4iPj8e1a9fw66+/ok+fPlCpVJg+fbq6z7Rp0/Dzzz/j+vXrOHToEAYMGAC5XI4hQ4boffuIiIjosfJGjjbUVBgGHSAnNDQUmZmZmDt3LtLT0+Ht7Y2EhAT1hdEpKSka1/cUFBRg9uzZuHbtGiwtLREcHIyNGzfC1tZW3efmzZsYMmQI7t69C3t7e3Tr1g1HjhyBvb29vjePiIiI/l/pyNEztz8+DWboqTBkQmibykzacnNzYWNjg5ycHF4PREREpEMztv2BuN9TMfLFJvigf1udrrsq39916i4wIiIiqttqy1QYDEBEREQkOQxAREREJDkMQERERCQ5DEBEREQkOQxAREREpDecC4yIiIgkhXOBERERkaRwLjAiIiKSHM4FRkRERJJT2+YCYwAiIiKiGlc6F1hpBjL0XGAMQERERKQXoZ0aY3BHVwDAiBebILRTY4PVwgBEREREesO5wIiIiIgMhAGIiIiIJIcBiIiIiPSGI0ETERGRpHAkaCIiIpIUjgRNREREksORoImIiEhyOBI0ERERSQ5HgiYiIiJJ4kjQREREJEkcCZqIiIjIQBiAiIiISHIYgIiIiEhyGICIiIhIbzgVBhEREUkKp8IgIiIiSeFUGERERCQ5nAqDiIiIJIdTYRAREZHkcCoMIiIikiROhUFERESSxKkw/t+yZcvg5uYGpVIJX19fHD16tNy+jx49wgcffAAPDw8olUq0b98eCQkJf2udREREJD0GDUBxcXGIiIhAVFQUTpw4gfbt2yMwMBB37tzR2n/27NlYtWoVli5dinPnzmHChAkYMGAATp48We11EhERkfQYNADFxMRg7NixCA8PR+vWrbFy5UqYm5tj7dq1Wvtv3LgRs2bNQnBwMNzd3TFx4kQEBwfjs88+q/Y6iYiISH8kPxJ0UVERjh8/joCAgP8VY2SEgIAAHD58WOsyhYWFUCqVGm1mZmZISkqq9jpL15ubm6vxICIiIt3iSNAAsrKyUFJSAkdHR412R0dHpKena10mMDAQMTExuHz5MlQqFfbu3Yv4+HikpaVVe50AEB0dDRsbG/XD1dX1b24dERERPYkjQf8NS5YsQfPmzeHp6QlTU1NMmTIF4eHhMDL6e5sRGRmJnJwc9SM1NVVHFRMRERHAkaDV7OzsIJfLkZGRodGekZEBJycnrcvY29tjx44dyMvLw40bN3DhwgVYWlrC3d292usEAIVCAWtra40HERER6Q5Hgv5/pqam8PHxQWJiorpNpVIhMTERfn5+FS6rVCrh4uKC4uJibN++Hf369fvb6yQiIqKaU9tGgjboKEQREREICwtDx44d0blzZ8TGxiIvLw/h4eEAgJEjR8LFxQXR0dEAgN9++w23bt2Ct7c3bt26hXnz5kGlUmH69OmVXicREREZRminxjhxIxtxv6cafCRogwag0NBQZGZmYu7cuUhPT4e3tzcSEhLUFzGnpKRoXN9TUFCA2bNn49q1a7C0tERwcDA2btwIW1vbSq+TiIiIDKe2jAQtE0KIZ3eTltzcXNjY2CAnJ4fXAxEREenQB9+dw9qDyZjUwwPT+3jqdN1V+f6uU3eBEREREekCAxARERHpjeRHgiYiIiJp4UjQREREJCkcCZqIiIgkhyNBExERkeRwJGgiIiKSnNo2EjQDEBEREelFaKfGGNzRFQAMPhI0AxARERHpTW0ZCZoBiIiIiCSHAYiIiIgkhwGIiIiI9IYjQRMREZGkcCRoIiIikhSOBE1ERESSw5GgiYiISHI4EjQRERFJDkeCJiIiIkniSNBEREQkSRwJmoiIiMhAGICIiIhIbzgQIhEREUkKB0IkIiIiSeFAiERERCQ5HAiRiIiIJIcDIRIREZHkcCBEIiIikiQOhEhERESSxIEQiYiIiAyEAYiIiIgkhwGIiIiI9IYjQRMREZGkcCRoIiIikhSOBP2UZcuWwc3NDUqlEr6+vjh69GiF/WNjY9GyZUuYmZnB1dUVU6dORUFBgfr1efPmQSaTaTw8PT1rejOIiIioArVtJGiD3oMWFxeHiIgIrFy5Er6+voiNjUVgYCAuXrwIBweHMv3/85//YObMmVi7di26dOmCS5cuYdSoUZDJZIiJiVH3a9OmDfbt26d+bmxs2FvtiIiIpK50JOgnQ5BkR4KOiYnB2LFjER4ejtatW2PlypUwNzfH2rVrtfY/dOgQunbtiqFDh8LNzQ29e/fGkCFDyhw1MjY2hpOTk/phZ2enj80hIiKicnAk6P9XVFSE48ePIyAg4H/FGBkhICAAhw8f1rpMly5dcPz4cXXguXbtGnbv3o3g4GCNfpcvX0bDhg3h7u6OYcOGISXFcBdZERER0WO1aSRog50bysrKQklJCRwdHTXaHR0dceHCBa3LDB06FFlZWejWrRuEECguLsaECRMwa9YsdR9fX1+sX78eLVu2RFpaGubPn4/u3bvj7NmzsLKy0rrewsJCFBYWqp/n5ubqYAuJiIjoaRwJuhoOHDiABQsWYPny5Thx4gTi4+Oxa9cufPjhh+o+QUFBGDRoENq1a4fAwEDs3r0b2dnZ2LJlS7nrjY6Oho2Njfrh6uqqj80hIiIiAzFY/LKzs4NcLkdGRoZGe0ZGBpycnLQuM2fOHIwYMQJjxowBAHh5eSEvLw/jxo3D+++/DyOjsnnO1tYWLVq0wJUrV8qtJTIyEhEREernubm5DEFERETPMYMdATI1NYWPjw8SExPVbSqVComJifDz89O6TH5+fpmQI5fLAQBCCG2L4MGDB7h69SqcnZ3LrUWhUMDa2lrjQURERM8vg56Ai4iIQFhYGDp27IjOnTsjNjYWeXl5CA8PBwCMHDkSLi4uiI6OBgCEhIQgJiYGHTp0gK+vL65cuYI5c+YgJCREHYSmTZuGkJAQNGnSBLdv30ZUVBTkcjmGDBlisO0kIiKi2sWgASg0NBSZmZmYO3cu0tPT4e3tjYSEBPWF0SkpKRpHfGbPng2ZTIbZs2fj1q1bsLe3R0hICD7++GN1n5s3b2LIkCG4e/cu7O3t0a1bNxw5cgT29vZ63z4iIiKqnWSivHNHEpabmwsbGxvk5OTwdBgREZEOffDdOaw9mIxJPTwwvY9uZ2qoyvd3nboLjIiIiEgXqnUKrKSkBOvXr0diYiLu3LkDlUql8fr+/ft1UhwRERFRTahWAHr77bexfv169O3bF23btoVMJnv2QkRERES1RLUC0ObNm7Fly5YyU1AQERER1QXVugbI1NQUzZo103UtRERE9JzLKywGADwoKDZoHdUKQO+++y6WLFlS7uCDRERERE+LO5aCLb+nAgA2HrmBuGOGm6y8WqfAkpKS8NNPP+GHH35AmzZtYGJiovF6fHy8ToojIiKi50NazkNExp9B6aETAWBW/Fm81MIezjZmeq+nWgHI1tYWAwYM0HUtRERE9JxKzsqD6qkTRyVC4HpWft0JQOvWrdN1HURERPQca2pnASMZNEKQXCaDm525Qer5WwMhZmZmIikpCUlJScjMzNRVTURERPSccbYxQ/RAL5QOnCMDsGBgW4Mc/QGqGYDy8vLw5ptvwtnZGS+99BJeeuklNGzYEKNHj0Z+fr6uayQiIqLnQGinxhjc0RUAMOLFJgjt1NhgtVQrAEVERODnn3/Gd999h+zsbGRnZ+O///0vfv75Z7z77ru6rpGIiIieExaKx1ffWCoNOh979a4B2r59O7Zt24YePXqo24KDg2FmZobBgwdjxYoVuqqPiIiISOeqdQQoPz8fjo6OZdodHBx4CoyIiIhqvWoFID8/P0RFRaGgoEDd9vDhQ8yfPx9+fn46K46IiIioJlTrFNiSJUsQGBiIRo0aoX379gCA06dPQ6lUYs+ePTotkIiIiEjXqhWA2rZti8uXL2PTpk24cOECAGDIkCEYNmwYzMwMczsbERERUWVV+xJsc3NzjB07Vpe1EBEREelFpQPQzp07ERQUBBMTE+zcubPCvv/4xz/+dmFERERENaXSAah///5IT0+Hg4MD+vfvX24/mUyGkpISXdRGREREVCMqHYBUKpXWfxMRERHVNX9rLrAnZWdn62pVRERERDWqWgFo0aJFiIuLUz8fNGgQ6tevDxcXF5w+fVpnxRERERHVhGoFoJUrV8LV9fFkZnv37sW+ffuQkJCAoKAgvPfeezotkIiIiEjXqnUbfHp6ujoAff/99xg8eDB69+4NNzc3+Pr66rRAIiIiIl2r1hGgevXqITU1FQCQkJCAgIAAAIAQgneAERERUa1XrSNAAwcOxNChQ9G8eXPcvXsXQUFBAICTJ0+iWbNmOi2QiIiISNeqFYA+//xzuLm5ITU1FZ988gksLS0BAGlpaZg0aZJOCyQiIiLStWoFIBMTE0ybNq1M+9SpU/92QUREREQ1jVNhEBERkd7kFRYDAB4UFBu0DpkQQlSmo5GRkXoqDCOj8q+dfh6mwsjNzYWNjQ1ycnJgbW1t6HKIiIieC3HHUjBz+xkIADIAC1/zQminxjpbf1W+vyt9F5hKpYKDg4P63+U96nr4ISIiIt1Ly3mIyPjH4QcABIBZ8WeRlvPQIPXobCoMIiIiovIkZ+VB9dQ5pxIhcD0r3yD1VCsAvfXWW/jiiy/KtH/55Zd45513/m5NRERE9JxpamcBI5lmm1wmg5uduUHqqVYA2r59O7p27VqmvUuXLti2bVuV1rVs2TK4ublBqVTC19cXR48erbB/bGwsWrZsCTMzM7i6umLq1KkoKCj4W+skIiKimuVsY4bogV4ozUAyAAsGtoWzjZlB6qlWALp79y5sbGzKtFtbWyMrK6vS64mLi0NERASioqJw4sQJtG/fHoGBgbhz547W/v/5z38wc+ZMREVF4fz581izZg3i4uIwa9asaq+TiIiI9CO0U2MM7vh4Kq0RLzbR6QXQVVWtANSsWTMkJCSUaf/hhx/g7u5e6fXExMRg7NixCA8PR+vWrbFy5UqYm5tj7dq1WvsfOnQIXbt2xdChQ+Hm5obevXtjyJAhGkd4qrpOIiIi0h8LxeMReCyV1RqKUGeq9e4RERGYMmUKMjMz0atXLwBAYmIiPvvsM8TGxlZqHUVFRTh+/DgiIyPVbUZGRggICMDhw4e1LtOlSxf8+9//xtGjR9G5c2dcu3YNu3fvxogRI6q9TgAoLCxEYWGh+nlubm6ltoGIiIjqpmoFoDfffBOFhYX4+OOP8eGHHwIA3NzcsGLFCowcObJS68jKykJJSQkcHR012h0dHXHhwgWtywwdOhRZWVno1q0bhBAoLi7GhAkT1KfAqrNOAIiOjsb8+fMrVTcRERHVfdW+DX7ixIm4efMmMjIykJubi2vXrlU6/FTXgQMHsGDBAixfvhwnTpxAfHw8du3apQ5h1RUZGYmcnBz1o3SmeyIiIno+VfsEXHFxMQ4cOICrV69i6NChAIDbt2/D2tpaPTlqRezs7CCXy5GRkaHRnpGRAScnJ63LzJkzByNGjMCYMWMAAF5eXsjLy8O4cePw/vvvV2udAKBQKKBQKJ5ZMxERET0fqnUE6MaNG/Dy8kK/fv0wefJkZGZmAgAWLVqkdZJUbUxNTeHj44PExER1m0qlQmJiIvz8/LQuk5+fX2YaDrlcDgAQQlRrnURERCQ91QpAb7/9Njp27Ii//voLZmb/u39/wIABGuHjWSIiIrB69Wps2LAB58+fx8SJE5GXl4fw8HAAwMiRIzUuaA4JCcGKFSuwefNmJCcnY+/evZgzZw5CQkLUQehZ6yQiIiKq1imwX3/9FYcOHYKpqalGu5ubG27dulXp9YSGhiIzMxNz585Feno6vL29kZCQoL6IOSUlReOIz+zZsyGTyTB79mzcunUL9vb2CAkJwccff1zpdRIRERFVejb4J9WrVw8HDx5E69atYWVlhdOnT8Pd3R1JSUl47bXXylyDU9dwNngiIqKa8cF357D2YDIm9fDA9D6eOl13jcwG/6TevXtrjPcjk8nw4MEDREVFITg4uDqrJCIiItKbap0CW7x4Mfr06YPWrVujoKAAQ4cOxeXLl2FnZ4dvvvlG1zUSERER6VS1ApCrqytOnz6NuLg4nD59Gg8ePMDo0aMxbNgwjYuiiYiIiGqjKgegR48ewdPTE99//z2GDRuGYcOG1URdRERERDWmytcAmZiYoKCgoCZqISIiItKLal0EPXnyZCxatAjFxcW6roeIiIioxlXrGqBjx44hMTERP/74I7y8vGBhYaHxenx8vE6KIyIiIqoJ1QpAtra2eO2113RdCxEREZFeVCkAqVQqfPrpp7h06RKKiorQq1cvzJs3j3d+ERERUaXkFT6+fOZBgWEvo6nSNUAff/wxZs2aBUtLS7i4uOCLL77A5MmTa6o2IiIieo7EHUvBlt9TAQAbj9xA3LEUg9VSpQD09ddfY/ny5dizZw927NiB7777Dps2bYJKpaqp+oiIiOg5kJbzEJHxZ1A6/5YAMCv+LNJyHhqknioFoJSUFI2pLgICAiCTyXD79m2dF0ZERETPj+SsPKiemn20RAhcz8o3SD1VCkDFxcVQKpUabSYmJnj06JFOiyIiIqLnS1M7CxjJNNvkMhnc7MwNUk+VLoIWQmDUqFFQKBTqtoKCAkyYMEHjVnjeBk9ERERPcrYxQ/RAL8zc/vg0mAzAgoFt4WxjmBupqhSAwsLCyrQNHz5cZ8UQERHR8yu0U2OcuJGNuN9TMeLFJgjt1NhgtVQpAK1bt66m6iAiIiIJsFA8jh6WymoNRagz1ZoKg4iIiKguYwAiIiIiyWEAIiIiIslhACIiIiLJYQAiIiIiyWEAIiIiIslhACIiIiLJYQAiIiIiyWEAIiIiIslhACIiIiLJYQAiIiIiyWEAIiIiIslhACIiIiLJYQAiIiIiyWEAIiIiIslhACIiIiLJYQAiIiIiyakVAWjZsmVwc3ODUqmEr68vjh49Wm7fHj16QCaTlXn07dtX3WfUqFFlXu/Tp48+NoWIiIjqAGNDFxAXF4eIiAisXLkSvr6+iI2NRWBgIC5evAgHB4cy/ePj41FUVKR+fvfuXbRv3x6DBg3S6NenTx+sW7dO/VyhUNTcRhAREVGdYvAjQDExMRg7dizCw8PRunVrrFy5Eubm5li7dq3W/vXr14eTk5P6sXfvXpibm5cJQAqFQqNfvXr19LE5REREVAcYNAAVFRXh+PHjCAgIULcZGRkhICAAhw8frtQ61qxZgzfeeAMWFhYa7QcOHICDgwNatmyJiRMn4u7duzqtnYiIiOoug54Cy8rKQklJCRwdHTXaHR0dceHChWcuf/ToUZw9exZr1qzRaO/Tpw8GDhyIpk2b4urVq5g1axaCgoJw+PBhyOXyMuspLCxEYWGh+nlubm41t4iIiIjqAoNfA/R3rFmzBl5eXujcubNG+xtvvKH+t5eXF9q1awcPDw8cOHAAL7/8cpn1REdHY/78+TVeLxEREdUOBj0FZmdnB7lcjoyMDI32jIwMODk5VbhsXl4eNm/ejNGjRz/zfdzd3WFnZ4crV65ofT0yMhI5OTnqR2pqauU3goiIiOocgwYgU1NT+Pj4IDExUd2mUqmQmJgIPz+/CpfdunUrCgsLMXz48Ge+z82bN3H37l04OztrfV2hUMDa2lrjQURERM8vg98FFhERgdWrV2PDhg04f/48Jk6ciLy8PISHhwMARo4cicjIyDLLrVmzBv3790eDBg002h88eID33nsPR44cwfXr15GYmIh+/fqhWbNmCAwM1Ms2ERERUe1m8GuAQkNDkZmZiblz5yI9PR3e3t5ISEhQXxidkpICIyPNnHbx4kUkJSXhxx9/LLM+uVyOP/74Axs2bEB2djYaNmyI3r1748MPP+RYQERERASgFgQgAJgyZQqmTJmi9bUDBw6UaWvZsiWEEFr7m5mZYc+ePbosj4iIiJ4zBj8FRkRERKRvDEBEREQkOQxAREREJDkMQERERCQ5DEBEREQkOQxAREREJDkMQERERCQ5DEBEREQkOQxAREREJDkMQERERCQ5DEBEREQkOQxAREREJDkMQERERCQ5DEBEREQkOQxAREREJDkMQERERCQ5DEBEREQkOQxAREREJDkMQERERCQ5DEBEREQkOQxAREREJDkMQERERCQ5DEBEREQkOQxAREREJDkMQERERCQ5DEBEREQkOQxAREREJDkMQERERCQ5DEBEREQkOQxAREREJDkMQERERCQ5DEBEREQkOQxAREREJDkMQERERCQ5tSIALVu2DG5ublAqlfD19cXRo0fL7dujRw/IZLIyj759+6r7CCEwd+5cODs7w8zMDAEBAbh8+bI+NoWIiIjqAIMHoLi4OERERCAqKgonTpxA+/btERgYiDt37mjtHx8fj7S0NPXj7NmzkMvlGDRokLrPJ598gi+++AIrV67Eb7/9BgsLCwQGBqKgoEBfm0VERES1mMEDUExMDMaOHYvw8HC0bt0aK1euhLm5OdauXau1f/369eHk5KR+7N27F+bm5uoAJIRAbGwsZs+ejX79+qFdu3b4+uuvcfv2bezYsUOPW0ZERES1lUEDUFFREY4fP46AgAB1m5GREQICAnD48OFKrWPNmjV44403YGFhAQBITk5Genq6xjptbGzg6+tb7joLCwuRm5ur8SAiIqLnl0EDUFZWFkpKSuDo6KjR7ujoiPT09Gcuf/ToUZw9exZjxoxRt5UuV5V1RkdHw8bGRv1wdXWt6qYQERFRHWLwU2B/x5o1a+Dl5YXOnTv/rfVERkYiJydH/UhNTdVRhURERFQbGTQA2dnZQS6XIyMjQ6M9IyMDTk5OFS6bl5eHzZs3Y/To0RrtpctVZZ0KhQLW1tYaDyIiInp+GTQAmZqawsfHB4mJieo2lUqFxMRE+Pn5Vbjs1q1bUVhYiOHDh2u0N23aFE5OThrrzM3NxW+//fbMdRIREZE0GBu6gIiICISFhaFjx47o3LkzYmNjkZeXh/DwcADAyJEj4eLigujoaI3l1qxZg/79+6NBgwYa7TKZDO+88w4++ugjNG/eHE2bNsWcOXPQsGFD9O/fX1+bRURERLWYwQNQaGgoMjMzMXfuXKSnp8Pb2xsJCQnqi5hTUlJgZKR5oOrixYtISkrCjz/+qHWd06dPR15eHsaNG4fs7Gx069YNCQkJUCqVNb49REREVPvJhBDC0EXUNrm5ubCxsUFOTg6vByIiItKhD747h7UHkzGphwem9/HU6bqr8v1dp+8CIyIiIqoOBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhyDB6Bly5bBzc0NSqUSvr6+OHr0aIX9s7OzMXnyZDg7O0OhUKBFixbYvXu3+vV58+ZBJpNpPDw9PWt6M4iIiKgOMTbkm8fFxSEiIgIrV66Er68vYmNjERgYiIsXL8LBwaFM/6KiIrzyyitwcHDAtm3b4OLighs3bsDW1lajX5s2bbBv3z71c2Njg24mERER1TIGTQYxMTEYO3YswsPDAQArV67Erl27sHbtWsycObNM/7Vr1+LevXs4dOgQTExMAABubm5l+hkbG8PJyalGayciIqK6y2CnwIqKinD8+HEEBAT8rxgjIwQEBODw4cNal9m5cyf8/PwwefJkODo6om3btliwYAFKSko0+l2+fBkNGzaEu7s7hg0bhpSUlBrdFiIiIqpbDHYEKCsrCyUlJXB0dNRod3R0xIULF7Quc+3aNezfvx/Dhg3D7t27ceXKFUyaNAmPHj1CVFQUAMDX1xfr169Hy5YtkZaWhvnz56N79+44e/YsrKystK63sLAQhYWF6ue5ubk62koiIiKqjerUxTEqlQoODg746quvIJfL4ePjg1u3buHTTz9VB6CgoCB1/3bt2sHX1xdNmjTBli1bMHr0aK3rjY6Oxvz58/WyDURERGR4BjsFZmdnB7lcjoyMDI32jIyMcq/fcXZ2RosWLSCXy9VtrVq1Qnp6OoqKirQuY2trixYtWuDKlSvl1hIZGYmcnBz1IzU1tRpbRERERHWFwQKQqakpfHx8kJiYqG5TqVRITEyEn5+f1mW6du2KK1euQKVSqdsuXboEZ2dnmJqaal3mwYMHuHr1KpydncutRaFQwNraWuNBREREzy+DjgMUERGB1atXY8OGDTh//jwmTpyIvLw89V1hI0eORGRkpLr/xIkTce/ePbz99tu4dOkSdu3ahQULFmDy5MnqPtOmTcPPP/+M69ev49ChQxgwYADkcjmGDBmi9+0jIiKi2smg1wCFhoYiMzMTc+fORXp6Ory9vZGQkKC+MDolJQVGRv/LaK6urtizZw+mTp2Kdu3awcXFBW+//TZmzJih7nPz5k0MGTIEd+/ehb29Pbp164YjR47A3t5e79tHREREtZNMCCEMXURtk5ubCxsbG+Tk5PB0GBERkQ598N05rD2YjEk9PDC9j25naqjK97fBp8IgIiIi0jcGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIi0pu8wmIAwIOCYoPWwQBEREREehF3LAVbfk8FAGw8cgNxx1IMVgsDEBEREdW4tJyHiIw/A/H/zwWAWfFnkZbz0CD1MAARERFRjUvOyoNKaLaVCIHrWfkGqYcBiIiIiGpcUzsLGMk02+QyGdzszA1SDwMQERER1ThnGzNED/SCXPY4BcllMiwY2BbONmYGqcfYIO9KREREkhPaqTFeamGP61n5cLMzN1j4ARiAiIiISI+cbcwMGnxK8RQYERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkOAxARERFJDgMQERERSQ4DEBEREUkO5wLTQggBAMjNzTVwJURERFRZpd/bpd/jFWEA0uL+/fsAAFdXVwNXQkRERFV1//592NjYVNhHJioTkyRGpVLh9u3bsLKygkwm0+m6c3Nz4erqitTUVFhbW+t03fQ/3M/6wf2sH9zP+sH9rB81uZ+FELh//z4aNmwII6OKr/LhESAtjIyM0KhRoxp9D2tra/6C6QH3s35wP+sH97N+cD/rR03t52cd+SnFi6CJiIhIchiAiIiISHIYgPRMoVAgKioKCoXC0KU817if9YP7WT+4n/WD+1k/ast+5kXQREREJDk8AkRERESSwwBEREREksMARERERJLDAERERESSwwBUA5YtWwY3NzcolUr4+vri6NGjFfbfunUrPD09oVQq4eXlhd27d+up0rqtKvt59erV6N69O+rVq4d69eohICDgmT8Xeqyqn+dSmzdvhkwmQ//+/Wu2wOdEVfdzdnY2Jk+eDGdnZygUCrRo0YJ/Oyqhqvs5NjYWLVu2hJmZGVxdXTF16lQUFBToqdq66ZdffkFISAgaNmwImUyGHTt2PHOZAwcO4IUXXoBCoUCzZs2wfv36Gq8TgnRq8+bNwtTUVKxdu1b8+eefYuzYscLW1lZkZGRo7X/w4EEhl8vFJ598Is6dOydmz54tTExMxJkzZ/Rced1S1f08dOhQsWzZMnHy5Elx/vx5MWrUKGFjYyNu3ryp58rrlqru51LJycnCxcVFdO/eXfTr108/xdZhVd3PhYWFomPHjiI4OFgkJSWJ5ORkceDAAXHq1Ck9V163VHU/b9q0SSgUCrFp0yaRnJws9uzZI5ydncXUqVP1XHndsnv3bvH++++L+Ph4AUB8++23Ffa/du2aMDc3FxEREeLcuXNi6dKlQi6Xi4SEhBqtkwFIxzp37iwmT56sfl5SUiIaNmwooqOjtfYfPHiw6Nu3r0abr6+vGD9+fI3WWddVdT8/rbi4WFhZWYkNGzbUVInPhers5+LiYtGlSxfxr3/9S4SFhTEAVUJV9/OKFSuEu7u7KCoq0leJz4Wq7ufJkyeLXr16abRFRESIrl271midz5PKBKDp06eLNm3aaLSFhoaKwMDAGqxMCJ4C06GioiIcP34cAQEB6jYjIyMEBATg8OHDWpc5fPiwRn8ACAwMLLc/VW8/Py0/Px+PHj1C/fr1a6rMOq+6+/mDDz6Ag4MDRo8erY8y67zq7OedO3fCz88PkydPhqOjI9q2bYsFCxagpKREX2XXOdXZz126dMHx48fVp8muXbuG3bt3Izg4WC81S4Whvgc5GaoOZWVloaSkBI6Ojhrtjo6OuHDhgtZl0tPTtfZPT0+vsTrruurs56fNmDEDDRs2LPNLR/9Tnf2clJSENWvW4NSpU3qo8PlQnf187do17N+/H8OGDcPu3btx5coVTJo0CY8ePUJUVJQ+yq5zqrOfhw4diqysLHTr1g1CCBQXF2PChAmYNWuWPkqWjPK+B3Nzc/Hw4UOYmZnVyPvyCBBJzsKFC7F582Z8++23UCqVhi7nuXH//n2MGDECq1evhp2dnaHLea6pVCo4ODjgq6++go+PD0JDQ/H+++9j5cqVhi7tuXLgwAEsWLAAy5cvx4kTJxAfH49du3bhww8/NHRppAM8AqRDdnZ2kMvlyMjI0GjPyMiAk5OT1mWcnJyq1J+qt59LLV68GAsXLsS+ffvQrl27miyzzqvqfr569SquX7+OkJAQdZtKpQIAGBsb4+LFi/Dw8KjZouug6nyenZ2dYWJiArlcrm5r1aoV0tPTUVRUBFNT0xqtuS6qzn6eM2cORowYgTFjxgAAvLy8kJeXh3HjxuH999+HkRGPIehCed+D1tbWNXb0B+ARIJ0yNTWFj48PEhMT1W0qlQqJiYnw8/PTuoyfn59GfwDYu3dvuf2pevsZAD755BN8+OGHSEhIQMeOHfVRap1W1f3s6emJM2fO4NSpU+rHP/7xD/Ts2ROnTp2Cq6urPsuvM6rzee7atSuuXLmiDpgAcOnSJTg7OzP8lKM6+zk/P79MyCkNnYLTaOqMwb4Ha/QSawnavHmzUCgUYv369eLcuXNi3LhxwtbWVqSnpwshhBgxYoSYOXOmuv/BgweFsbGxWLx4sTh//ryIioribfCVUNX9vHDhQmFqaiq2bdsm0tLS1I/79+8bahPqhKru56fxLrDKqep+TklJEVZWVmLKlCni4sWL4vvvvxcODg7io48+MtQm1AlV3c9RUVHCyspKfPPNN+LatWvixx9/FB4eHmLw4MGG2oQ64f79++LkyZPi5MmTAoCIiYkRJ0+eFDdu3BBCCDFz5kwxYsQIdf/S2+Dfe+89cf78ebFs2TLeBl9XLV26VDRu3FiYmpqKzp07iyNHjqhf8/f3F2FhYRr9t2zZIlq0aCFMTU1FmzZtxK5du/Rccd1Ulf3cpEkTAaDMIyoqSv+F1zFV/Tw/iQGo8qq6nw8dOiR8fX2FQqEQ7u7u4uOPPxbFxcV6rrruqcp+fvTokZg3b57w8PAQSqVSuLq6ikmTJom//vpL/4XXIT/99JPWv7el+zYsLEz4+/uXWcbb21uYmpoKd3d3sW7duhqvUyYEj+MRERGRtPAaICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiokqSyWTYsWMHAOD69euQyWQ4deqUQWsiouphACKiOmHUqFGQyWSQyWQwMTFB06ZNMX36dBQUFBi6NCKqgzgbPBHVGX369MG6devw6NEjHD9+HGFhYZDJZFi0aJGhSyOiOoZHgIiozlAoFHBycoKrqyv69++PgIAA7N27F8Djmb2jo6PRtGlTmJmZoX379ti2bZvG8n/++SdeffVVWFtbw8rKCt27d8fVq1cBAMeOHcMrr7wCOzs72NjYwN/fHydOnND7NhKRfjAAEVGddPbsWRw6dAimpqYAgOjoaHz99ddYuXIl/vzzT0ydOhXDhw/Hzz//DAC4desWXnrpJSgUCuzfvx/Hjx/Hm2++ieLiYgDA/fv3ERYWhqSkJBw5cgTNmzdHcHAw7t+/b7BtJKKaw1NgRFRnfP/997C0tERxcTEKCwthZGSEL7/8EoWFhViwYAH27dsHPz8/AIC7uzuSkpKwatUq+Pv7Y9myZbCxscHmzZthYmICAGjRooV63b169dJ4r6+++gq2trb4+eef8eqrr+pvI4lILxiAiKjO6NmzJ1asWIG8vDx8/vnnMDY2xmuvvYY///wT+fn5eOWVVzT6FxUVoUOHDgCAU6dOoXv37urw87SMjAzMnj0bBw4cwJ07d1BSUoL8/HykpKTU+HYRkf4xABFRnWFhYYFmzZoBANauXYv27dtjzZo1aNu2LQBg165dcHFx0VhGoVAAAMzMzCpcd1hYGO7evYslS5agSZMmUCgU8PPzQ1FRUQ1sCREZGgMQEdVJRkZGmDVrFiIiInDp0iUoFAqkpKTA399fa/927dphw4YNePTokdajQAcPHsTy5csRHBwMAEhNTUVWVlaNbgMRGQ4vgiaiOmvQoEGQy+VYtWoVpk2bhqlTp2LDhg24evUqTpw4gaVLl2LDhg0AgClTpiA3NxdvvPEGfv/9d1y+fBkbN27ExYsXAQDNmzfHxo0bcf78efz2228YNmzYM48aEVHdxSNARFRnGRsbY8qUKfjkk0+QnJwMe3t7REdH49q1a7C1tcULL7yAWbNmAQAaNGiA/fv347333oO/vz/kcjm8vb3RtWtXAMCaNWswbtw4vPDCC3B1dcWCBQswbdo0Q24eEdUgmRBCGLoIIiIiIn3iKTAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpIcBiAiIiKSHAYgIiIikhwGICIiIpKc/wPgN9JSyMTpTAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 23. Train a Random Forest Classifier and plot the Precision-Recall curve\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "y_prob = rf_clf.predict_proba(X_test)[:, 1]\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve for Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31d22907-3a78-4131-b161-c364140ea1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 0.956140350877193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 24. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=[\n",
    "    ('random_forest', RandomForestClassifier(n_estimators=100)),\n",
    "    ('log_reg', LogisticRegression())\n",
    "], final_estimator=LogisticRegression())\n",
    "\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "print(\"Stacking Classifier Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7821eb8-8482-4ece-b722-b24b56da74ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Regressor MSE with 50.0% bootstrap samples: 0.031754385964912285\n",
      "Bagging Regressor MSE with 70.0% bootstrap samples: 0.03140350877192982\n",
      "Bagging Regressor MSE with 100.0% bootstrap samples: 0.03578947368421054\n"
     ]
    }
   ],
   "source": [
    "# 25. Train a Bagging Regressor with different levels of bootstrap samples and compare performance\n",
    "\n",
    "bootstrap_samples = [0.5, 0.7, 1.0]\n",
    "for bs in bootstrap_samples:\n",
    "    bag_reg = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=10, max_samples=bs)\n",
    "    bag_reg.fit(X_train, y_train)\n",
    "    y_pred = bag_reg.predict(X_test)\n",
    "    print(f\"Bagging Regressor MSE with {bs*100}% bootstrap samples:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6029e7f2-5e3c-4cb7-a7a2-4ce3437d3a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

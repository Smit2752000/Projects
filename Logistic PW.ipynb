{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ece35f48-47ce-4e70-8477-d4bd2c22bb5a",
   "metadata": {},
   "source": [
    "\n",
    "Theory Answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e08766-0310-493c-a6c6-ac565338a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-1=What is Logistic Regression, and how does it differ from Linear Regression?\n",
    "ans=Logistic Regression is a classification algorithm used to predict categorical outcomes (like Yes/No, Spam/Not Spam). It calculates probabilities using the sigmoid function,\n",
    "which outputs values between 0 and 1.Linear Regression is for numerical predictions, while Logistic Regression is for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567b1073-b296-4e4c-b24d-30739876f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-2=What is the mathematical equation of Logistic Regression?\n",
    "ans=def logistic_regression(X, b):\n",
    "    return 1 / (1 + np.exp(-(b[0] + np.dot(X, b[1:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e45f10-59a6-45a8-a039-fc56d136551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-3=Why do we use the Sigmoid function in Logistic Regression?\n",
    "ans=We use the Sigmoid function in Logistic Regression because it maps any real-valued number to a range between 0 and 1, making it ideal for probability estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0cfae3-33d0-4f65-8e45-db1c65f775a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-4=What is the cost function of Logistic Regression?\n",
    "ans=The cost function for Logistic Regression is the Log Loss (Binary Cross-Entropy) function, which measures how well the model's predicted probabilities match the actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a017860e-8ab2-484b-bd79-bec4214f87dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-5=What is Regularization in Logistic Regression? Why is it needed?\n",
    "ans=Regularization prevents overfitting by adding a penalty to large coefficients.\n",
    "Types:\n",
    "L1 (Lasso) – Shrinks some coefficients to zero (feature selection).\n",
    "L2 (Ridge) – Reduces coefficient values but keeps them nonzero.\n",
    "Why Needed?\n",
    "Improves generalization.\n",
    "Prevents overfitting.\n",
    "Handles multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2a8c40-2236-4401-80b0-e52bdc237a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-6=Explain the difference between Lasso, Ridge, and Elastic Net regression?\n",
    "ans=Lasso (L1) adds a penalty that can shrink some coefficients to zero, effectively selecting important features. Ridge (L2) applies a squared penalty, shrinking coefficients but never making them zero, which helps handle multicollinearity.\n",
    "Elastic Net combines both L1 and L2, balancing feature selection and coefficient shrinkage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ab339b-ab8d-4fac-99dd-9c6fb999d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-7=When should we use Elastic Net instead of Lasso or Ridge?\n",
    "ans=Use Elastic Net when:\n",
    "Lasso selects too few features (L1 may shrink too many coefficients to zero).\n",
    "Ridge doesn’t eliminate irrelevant features (L2 only shrinks, not removes).\n",
    "Your dataset has correlated features (Elastic Net balances feature selection & shrinkage).\n",
    "You need a flexible model combining benefits of both Lasso (sparsity) and Ridge (stability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96838f80-3fe1-4a5a-8b27-9eace66280d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-8=What is the impact of the regularization parameter (λ) in Logistic Regression.\n",
    "ans=The regularization parameter (λ) in Logistic Regression controls the strength of the penalty on large coefficients:\n",
    "High λ (Strong Regularization) → Shrinks coefficients more, reduces overfitting but may underfit.\n",
    "Low λ (Weak Regularization) → Keeps coefficients larger, improves fit but may overfit.\n",
    "λ = 0 → No regularization, behaves like standard Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad0f7c-3a07-47f1-8d26-2647c4acd0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-9=What are the key assumptions of Logistic Regression?\n",
    "ans=Key Assumptions of Logistic Regression:\n",
    "Linear relationship between independent variables and log-odds.\n",
    "Independent observations (no duplicate or correlated samples).\n",
    "No multicollinearity between independent variables.\n",
    "Large sample size for stable predictions.\n",
    "Binary or ordinal target variable (0/1 or categories).\n",
    "No extreme outliers that can distort predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90022505-219f-44af-be68-ed12f3722fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-10=What are some alternatives to Logistic Regression for classification tasks?\n",
    "ans=Alternatives to Logistic Regression for Classification:\n",
    "Decision Trees – Handles non-linearity and works well with small datasets.\n",
    "Random Forest – An ensemble of decision trees for better accuracy.\n",
    "Support Vector Machine (SVM) – Effective for high-dimensional data.\n",
    "K-Nearest Neighbors (KNN) – Simple, instance-based learning.\n",
    "Naïve Bayes – Best for text classification and probabilistic modeling.\n",
    "Neural Networks (Deep Learning) – Powerful for complex and large datasets.\n",
    "Gradient Boosting (XGBoost, LightGBM, CatBoost) – High-performance ensemble models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49acfdf-000f-4a7d-91ff-f7ca97365dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-11=What are Classification Evaluation Metrics?\n",
    "ans=Classification Evaluation Metrics:\n",
    "Accuracy – Measures the overall correctness of predictions.\n",
    "Precision – Focuses on how many predicted positives are actually correct.\n",
    "Recall (Sensitivity) – Measures how well the model identifies actual positives.\n",
    "F1-Score – Balances Precision and Recall, useful for imbalanced data.\n",
    "ROC-AUC Score – Evaluates the model’s ability to distinguish between classes.\n",
    "Confusion Matrix – Provides a detailed breakdown of correct and incorrect predictions.\n",
    "Log Loss – Measures the uncertainty of probabilistic predictions (lower is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7d0c3-ea0a-4b4d-9715-99836a504efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-12=How does class imbalance affect Logistic Regression?\n",
    "ans=Effect of Class Imbalance on Logistic Regression:\n",
    "Biased Predictions – The model favors the majority class, leading to poor detection of the minority class.\n",
    "High Accuracy Misleading – Accuracy may appear high but fails to capture minority class performance.\n",
    "Poor Recall for Minority Class – The model struggles to correctly identify minority class instances.\n",
    "Skewed Decision Boundary – The learned boundary may not properly separate both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f166f2d5-3b6e-4d80-9c85-25e97ce57200",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-13=What is Hyperparameter Tuning in Logistic Regression?\n",
    "ans=Hyperparameter tuning is the process of optimizing model parameters to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca31211-1a92-4f5b-891f-468caaf89338",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-14= What are different solvers in Logistic Regression? Which one should be used?\n",
    "ans=liblinear – Best for small datasets, supports L1 & L2 regularization.\n",
    "lbfgs – Default solver, good for large datasets, supports only L2.\n",
    "newton-cg – Efficient for large datasets, supports only L2.\n",
    "sag – Best for very large datasets, works with only L2.\n",
    "saga – Supports both L1 & L2, best for large-scale problems.\n",
    "Small dataset - liblinear\n",
    "Large dataset - lbfgs, sag, or newton-cg\n",
    "L1 regularization - liblinear or saga\n",
    "Both L1 & L2 - saga (best for large data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ed6b81-c19f-4db5-9e35-8731691a466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-15=How is Logistic Regression extended for multiclass classification?\n",
    "ans=Logistic Regression is naturally for binary classification but can be extended to multiclass classification using two main strategies:\n",
    "One-vs-Rest (OvR) / One-vs-All (OvA)\n",
    "Trains one classifier per class (class vs. all others).\n",
    "Final prediction is the class with the highest probability.\n",
    "Default method in Scikit-Learn (multi_class='ovr').\n",
    "Works well for most cases.\n",
    "One-vs-One (OvO)\n",
    "Trains one classifier per class pair (C(C-1)/2 models).\n",
    "Final prediction is based on majority voting from all models.\n",
    "Used for small datasets with few classes.\n",
    "Softmax Regression (Multinomial Logistic Regression)\n",
    "Directly predicts probabilities for all classes at once.\n",
    "Uses the Softmax function instead of the Sigmoid.\n",
    "More efficient than OvR for truly multiclass problems.\n",
    "Used by setting multi_class='multinomial' in Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5747c9c-789a-4bdf-900c-eeb19792cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-16=What are the advantages and disadvantages of Logistic Regression?\n",
    "Ans=Advantages:\n",
    "Simple, interpretable, and easy to implement.\n",
    "Works well with small to medium datasets.\n",
    "Fast training with low computational cost.\n",
    "Provides probabilistic predictions.\n",
    "Coefficients show feature importance.\n",
    "Disadvantages:\n",
    "Assumes a linear relationship (log-odds).\n",
    "Sensitive to outliers.\n",
    "Not ideal for large or high-dimensional data.\n",
    "Struggles with complex patterns.\n",
    "Requires good feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbec5020-098b-434d-a312-fd43b52ac472",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-17=What are some use cases of Logistic Regression?\n",
    "ans=Use Cases of Logistic Regression:\n",
    "Medical Diagnosis – Predicts diseases (e.g., diabetes, cancer detection).\n",
    "Spam Detection – Classifies emails as spam or not spam.\n",
    "Credit Scoring – Determines loan approval based on credit history.\n",
    "Churn Prediction – Identifies customers likely to leave a service.\n",
    "Fraud Detection – Flags fraudulent transactions in banking.\n",
    "Marketing & Customer Segmentation – Predicts customer responses to campaigns.\n",
    "Employee Attrition – Identifies employees likely to leave a company.\n",
    "Sentiment Analysis – Classifies text as positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b12a90b-20ff-4a95-8702-f4450d91a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-18=What is the difference between Softmax Regression and Logistic Regression?\n",
    "ans=Usage: Logistic Regression is for binary classification, while Softmax Regression is for multiclass classification (3 or more classes).\n",
    "Output Function: Logistic Regression uses the Sigmoid function, whereas Softmax Regression uses the Softmax function to assign probabilities to multiple classes.\n",
    "Prediction: Logistic Regression predicts the probability of one class (0 or 1), while Softmax Regression predicts probabilities for all classes and selects the one with the highest probability.\n",
    "Decision Rule: Logistic Regression applies a probability threshold (e.g., >0.5), whereas Softmax Regression assigns the class with the highest probability.\n",
    "Implementation: In Scikit-Learn, Logistic Regression uses multi_class='ovr', while Softmax Regression uses multi_class='multinomial'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dcbaf2-a71f-416e-897d-16e3f19ede26",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-19= How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n",
    "ans=If speed & simplicity are priorities then use OvR\n",
    "If accuracy & proper multiclass probability handling are important then use Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebcdb4e-6f3e-4c22-9a2e-6ec1823880f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q-20=How do we interpret coefficients in Logistic Regression?\n",
    "ans=Interpreting Coefficients in Logistic Regression\n",
    "Each coefficient represents the impact of a feature on the log-odds of the target class.\n",
    "A positive coefficient means the feature increases the likelihood of the positive class.\n",
    "A negative coefficient means the feature decreases the likelihood of the positive class.\n",
    "The magnitude of the coefficient indicates the strength of the impact.\n",
    "To interpret in terms of probability, we use exponentiation, which gives the odds ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ec5e94-775d-41da-a2e6-8bf4dd534e07",
   "metadata": {},
   "source": [
    "\n",
    "Practical Answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5211de46-e9dd-418d-9f1e-a5b8c7498310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, precision_recall_curve, cohen_kappa_score, matthews_corrcoef\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc8177b6-a69f-412d-9c8c-aedd1c365bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bb14b7c-e377-49ea-9708-b52bc903bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1 & 8: Train Logistic Regression and print accuracy\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae83611b-bf47-4a0f-acda-9db60fb47a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy (Q1 & Q8): 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(f'Model Accuracy (Q1 & Q8): {accuracy_score(y_test, model.predict(X_test)):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bf125c6-5f8b-4fb2-9c3b-a0f2d0a4aa08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy with L1 (Q2): 1.0000\n",
      "Model Accuracy with L2 (Q3): 1.0000\n",
      "Coefficients (Q3): [[-0.39347744  0.96248927 -2.37513361 -0.99874691]\n",
      " [ 0.50844553 -0.2548109  -0.21300984 -0.77574616]\n",
      " [-0.11496809 -0.70767836  2.58814346  1.77449307]]\n"
     ]
    }
   ],
   "source": [
    "# Question 2 & 3: Train Logistic Regression with L1 & L2 Regularization\n",
    "model_l1 = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "model_l1.fit(X_train, y_train)\n",
    "print(f'Model Accuracy with L1 (Q2): {accuracy_score(y_test, model_l1.predict(X_test)):.4f}')\n",
    "\n",
    "model_l2 = LogisticRegression(penalty='l2')\n",
    "model_l2.fit(X_train, y_train)\n",
    "print(f'Model Accuracy with L2 (Q3): {accuracy_score(y_test, model_l2.predict(X_test)):.4f}')\n",
    "print(f'Coefficients (Q3): {model_l2.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdccb4ca-5de9-4324-a071-fc6097e18720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy with Elastic Net (Q4): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Question 4: Elastic Net Regularization\n",
    "model_elastic = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
    "model_elastic.fit(X_train, y_train)\n",
    "print(f'Model Accuracy with Elastic Net (Q4): {accuracy_score(y_test, model_elastic.predict(X_test)):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57b50fcb-d22a-474c-b6ce-231886a3a266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass OVR Accuracy (Q5): 0.9667\n"
     ]
    }
   ],
   "source": [
    "# Question 5: Multiclass OVR\n",
    "model_ovr = LogisticRegression(multi_class='ovr')\n",
    "model_ovr.fit(X_train, y_train)\n",
    "print(f'Multiclass OVR Accuracy (Q5): {accuracy_score(y_test, model_ovr.predict(X_test)):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c5dddf1-a040-4e0f-8df9-86c529712e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Q6): {'C': 1000.0, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Question 6 & 9: Hyperparameter Tuning with GridSearchCV & RandomizedSearchCV\n",
    "param_grid = {'C': np.logspace(-3, 3, 7), 'penalty': ['l1', 'l2']}\n",
    "grid_search = GridSearchCV(LogisticRegression(solver='liblinear'), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f'Best Parameters (Q6): {grid_search.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76c495f1-6b21-41f1-83f2-aab74583363c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Q9): {'solver': 'saga', 'penalty': 'l1', 'C': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_dist = {'C': np.logspace(-3, 3, 7), 'penalty': ['l1', 'l2'], 'solver': ['liblinear', 'saga']}\n",
    "random_search = RandomizedSearchCV(LogisticRegression(), param_distributions=param_dist, n_iter=10, cv=5)\n",
    "random_search.fit(X_train, y_train)\n",
    "print(f'Best Parameters (Q9): {random_search.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb61b3b2-4fb9-4d7f-a1d5-244d75bf8875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy (Q7): 0.9733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Question 7: Stratified K-Fold Cross Validation\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "cross_val_acc = cross_val_score(model_l2, X, y, cv=skf).mean()\n",
    "print(f'Cross-Validation Accuracy (Q7): {cross_val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b825186-cef7-4ed8-9b92-11e7b238ec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-vs-One Accuracy (Q10): 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Question 10: One-vs-One Multiclass Logistic Regression\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "ovo_model = OneVsOneClassifier(LogisticRegression())\n",
    "ovo_model.fit(X_train, y_train)\n",
    "print(f'One-vs-One Accuracy (Q10): {accuracy_score(y_test, ovo_model.predict(X_test)):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d3b1c2a-bb49-4eae-a1ba-52d500a57a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question 11: Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, model_l2.predict(X_test))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Q11)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb6079e7-2235-47a2-8644-998f8d3e962f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Q12):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question 12: Classification Report\n",
    "print(f'Classification Report (Q12):\\n{classification_report(y_test, model_l2.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "954305f6-5414-43a6-86eb-4b0ca2383b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic Model Accuracy (Q14): 0.7552\n"
     ]
    }
   ],
   "source": [
    "# Question 14: Logistic Regression on Titanic Dataset\n",
    "import seaborn as sns\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic.dropna(subset=['age', 'fare', 'sex', 'class', 'survived'], inplace=True)\n",
    "titanic['sex'] = titanic['sex'].map({'male': 0, 'female': 1})\n",
    "titanic['class'] = titanic['class'].map({'Third': 3, 'Second': 2, 'First': 1})\n",
    "X_titanic = titanic[['age', 'fare', 'sex', 'class']]\n",
    "y_titanic = titanic['survived']\n",
    "X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(X_titanic, y_titanic, test_size=0.2, random_state=42)\n",
    "model_titanic = LogisticRegression()\n",
    "model_titanic.fit(X_train_t, y_train_t)\n",
    "print(f'Titanic Model Accuracy (Q14): {accuracy_score(y_test_t, model_titanic.predict(X_test_t)):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "051d73c7-c754-4407-8f4d-b12465ceb154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data Accuracy (Q23): 1.0000\n",
      "Scaled Data Accuracy (Q23): 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Question 23: Compare Raw vs Standardized Data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model_scaled = LogisticRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "print(f'Raw Data Accuracy (Q23): {accuracy_score(y_test, model.predict(X_test)):.4f}')\n",
    "print(f'Scaled Data Accuracy (Q23): {accuracy_score(y_test, model_scaled.predict(X_test_scaled)):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bef263f-b3ba-4e99-9086-dc64199684cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal C Value (Q24): 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SMIT KUMAR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Question 24: Optimal C using Cross-Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "c_values = np.logspace(-3, 3, 7)\n",
    "best_c = max(c_values, key=lambda c: np.mean(cross_val_score(LogisticRegression(C=c), X, y, cv=5)))\n",
    "print(f'Optimal C Value (Q24): {best_c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d67033d-321f-4389-9856-48c081f2f0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy after Loading (Q25): 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Question 25: Save and Load Model\n",
    "joblib.dump(model, 'logistic_model.pkl')\n",
    "loaded_model = joblib.load('logistic_model.pkl')\n",
    "predictions = loaded_model.predict(X_test)\n",
    "print(f'Model Accuracy after Loading (Q25): {accuracy_score(y_test, predictions):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185d08e2-b9d1-44d4-8681-6027cf557228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
